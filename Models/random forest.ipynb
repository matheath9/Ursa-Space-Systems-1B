{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdYl0DgARr0Y",
        "outputId": "f01a6ef7-1cba-487a-c3ac-7fa9e2dc50e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV7Bp97uSGs0",
        "outputId": "669e9e5b-4ad5-49d8-8a53-c3df6b3121af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/saurabhbagchi/ship-and-iceberg-images?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 404M/404M [00:03<00:00, 127MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/saurabhbagchi/ship-and-iceberg-images/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version of the dataset\n",
        "path = kagglehub.dataset_download(\"saurabhbagchi/ship-and-iceberg-images\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8eOAEKVSdK2",
        "outputId": "1dfa3e5d-aa63-47ef-ea8b-3f831cd6b2e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We have 4113 examples to work with\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# ðŸ‘‡ replace with YOUR path from Step 2\n",
        "# Add '/input_data.npz' at the end of the path\n",
        "npz_path = \"/root/.cache/kagglehub/datasets/saurabhbagchi/ship-and-iceberg-images/versions/1/input_data.npz\"\n",
        "\n",
        "npz = np.load(npz_path)\n",
        "\n",
        "X_train = npz['X_train']\n",
        "Y_train = npz['Y_train']\n",
        "del npz\n",
        "\n",
        "print('We have {} examples to work with'.format(Y_train.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Qbq3KzjNTVcc",
        "outputId": "6b1e7e96-42e0-464d-d3eb-fb0fbb57a8f4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# This code will display the iceberg or vessel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels=['Ship', 'Iceberg']\n",
        "\n",
        "ix=100 # ID for specific image\n",
        "plt.imshow(np.squeeze(X_train[ix, :, :, 2]), cmap='gray')\n",
        "plt.title(f\"This is: {labels[int(Y_train[ix])]}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "Let's explore the Ship vs Iceberg dataset to understand its characteristics, distribution, and patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic Dataset Information\n",
        "print(\"=== DATASET OVERVIEW ===\")\n",
        "print(f\"Training images shape: {X_train.shape}\")\n",
        "print(f\"Training labels shape: {Y_train.shape}\")\n",
        "print(f\"Data type of images: {X_train.dtype}\")\n",
        "print(f\"Data type of labels: {Y_train.dtype}\")\n",
        "print(f\"Image dimensions: {X_train.shape[1]} x {X_train.shape[2]} pixels\")\n",
        "print(f\"Number of channels: {X_train.shape[3]}\")\n",
        "print()\n",
        "\n",
        "# Memory usage\n",
        "print(\"=== MEMORY USAGE ===\")\n",
        "print(f\"Images memory usage: {X_train.nbytes / (1024**2):.2f} MB\")\n",
        "print(f\"Labels memory usage: {Y_train.nbytes / (1024**2):.4f} MB\")\n",
        "print()\n",
        "\n",
        "# Value ranges\n",
        "print(\"=== DATA RANGES ===\")\n",
        "print(f\"Image pixel value range: [{X_train.min():.4f}, {X_train.max():.4f}]\")\n",
        "print(f\"Label value range: [{Y_train.min()}, {Y_train.max()}]\")\n",
        "print(f\"Unique labels: {np.unique(Y_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Class Distribution Analysis\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use('default')\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Count and percentage of each class\n",
        "class_counts = np.bincount(Y_train.astype(int))\n",
        "class_labels = ['Ship (0)', 'Iceberg (1)']\n",
        "percentages = (class_counts / len(Y_train)) * 100\n",
        "\n",
        "print(\"=== CLASS DISTRIBUTION ===\")\n",
        "for i, (label, count, pct) in enumerate(zip(class_labels, class_counts, percentages)):\n",
        "    print(f\"{label}: {count} samples ({pct:.1f}%)\")\n",
        "\n",
        "# Bar plot\n",
        "axes[0].bar(class_labels, class_counts, color=['skyblue', 'lightcoral'])\n",
        "axes[0].set_title('Class Distribution (Count)', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('Number of Samples')\n",
        "for i, count in enumerate(class_counts):\n",
        "    axes[0].text(i, count + 10, str(count), ha='center', fontweight='bold')\n",
        "\n",
        "# Pie chart\n",
        "colors = ['skyblue', 'lightcoral']\n",
        "axes[1].pie(class_counts, labels=class_labels, autopct='%1.1f%%', \n",
        "           colors=colors, startangle=90)\n",
        "axes[1].set_title('Class Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Check for class imbalance\n",
        "imbalance_ratio = max(class_counts) / min(class_counts)\n",
        "print(f\"\\nClass imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
        "if imbalance_ratio > 1.5:\n",
        "    print(\"âš ï¸  Dataset shows class imbalance - consider balancing techniques\")\n",
        "else:\n",
        "    print(\"âœ… Dataset is relatively balanced\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Sample Images Visualization\n",
        "def plot_sample_images(X, y, num_samples=8, figsize=(16, 8)):\n",
        "    \"\"\"\n",
        "    Plot sample images for each class to visualize the differences between ships and icebergs\n",
        "    \n",
        "    Parameters:\n",
        "    - X: Input images array (samples, height, width, channels)\n",
        "    - y: Labels array (0 for ships, 1 for icebergs)\n",
        "    - num_samples: Number of sample images to show per class\n",
        "    - figsize: Figure size for the plot\n",
        "    \"\"\"\n",
        "    # Create a subplot grid: 2 rows (one for each class) x num_samples columns\n",
        "    fig, axes = plt.subplots(2, num_samples, figsize=figsize)\n",
        "    \n",
        "    # Find all indices where labels are 0 (ships) and 1 (icebergs)\n",
        "    ship_indices = np.where(y == 0)[0]        # Get all ship image indices\n",
        "    iceberg_indices = np.where(y == 1)[0]     # Get all iceberg image indices\n",
        "    \n",
        "    # Randomly select sample images from each class without replacement\n",
        "    # This ensures we get different examples each time we run the function\n",
        "    ship_samples = np.random.choice(ship_indices, num_samples, replace=False)\n",
        "    iceberg_samples = np.random.choice(iceberg_indices, num_samples, replace=False)\n",
        "    \n",
        "    # Plot ship images in the top row (row 0)\n",
        "    for i, idx in enumerate(ship_samples):\n",
        "        # Extract channel 2 (3rd channel) and remove single dimensions using squeeze\n",
        "        # Channel 2 is often the most informative in radar imagery\n",
        "        image_data = np.squeeze(X[idx, :, :, 2])\n",
        "        \n",
        "        # Display the image in grayscale colormap\n",
        "        axes[0, i].imshow(image_data, cmap='gray')\n",
        "        axes[0, i].set_title(f'Ship #{idx}', fontsize=10)\n",
        "        axes[0, i].axis('off')  # Remove axis ticks and labels for cleaner look\n",
        "    \n",
        "    # Plot iceberg images in the bottom row (row 1)\n",
        "    for i, idx in enumerate(iceberg_samples):\n",
        "        # Extract channel 2 data for iceberg images\n",
        "        image_data = np.squeeze(X[idx, :, :, 2])\n",
        "        \n",
        "        # Display the image in grayscale colormap\n",
        "        axes[1, i].imshow(image_data, cmap='gray')\n",
        "        axes[1, i].set_title(f'Iceberg #{idx}', fontsize=10)\n",
        "        axes[1, i].axis('off')  # Remove axis ticks and labels for cleaner look\n",
        "    \n",
        "    # Add a main title for the entire figure\n",
        "    plt.suptitle('Sample Images from Each Class (Channel 2)', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()  # Adjust spacing between subplots\n",
        "    plt.show()\n",
        "\n",
        "# Execute the function to display random sample images from both classes\n",
        "# This helps us visually understand the differences between ships and icebergs\n",
        "plot_sample_images(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Pixel Intensity Analysis\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# Analyze each channel\n",
        "for channel in range(3):\n",
        "    # Overall distribution\n",
        "    axes[0, channel].hist(X_train[:, :, :, channel].flatten(), bins=50, alpha=0.7, density=True)\n",
        "    axes[0, channel].set_title(f'Channel {channel} - Overall Pixel Distribution', fontweight='bold')\n",
        "    axes[0, channel].set_xlabel('Pixel Intensity')\n",
        "    axes[0, channel].set_ylabel('Density')\n",
        "    axes[0, channel].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Class-wise distribution\n",
        "    ship_pixels = X_train[Y_train == 0, :, :, channel].flatten()\n",
        "    iceberg_pixels = X_train[Y_train == 1, :, :, channel].flatten()\n",
        "    \n",
        "    axes[1, channel].hist(ship_pixels, bins=50, alpha=0.6, label='Ships', density=True, color='skyblue')\n",
        "    axes[1, channel].hist(iceberg_pixels, bins=50, alpha=0.6, label='Icebergs', density=True, color='lightcoral')\n",
        "    axes[1, channel].set_title(f'Channel {channel} - Class-wise Pixel Distribution', fontweight='bold')\n",
        "    axes[1, channel].set_xlabel('Pixel Intensity')\n",
        "    axes[1, channel].set_ylabel('Density')\n",
        "    axes[1, channel].legend()\n",
        "    axes[1, channel].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistical summary\n",
        "print(\"=== PIXEL INTENSITY STATISTICS BY CHANNEL ===\")\n",
        "for channel in range(3):\n",
        "    print(f\"\\nChannel {channel}:\")\n",
        "    print(f\"  Mean: {X_train[:, :, :, channel].mean():.4f}\")\n",
        "    print(f\"  Std:  {X_train[:, :, :, channel].std():.4f}\")\n",
        "    print(f\"  Min:  {X_train[:, :, :, channel].min():.4f}\")\n",
        "    print(f\"  Max:  {X_train[:, :, :, channel].max():.4f}\")\n",
        "    \n",
        "    # Class-wise statistics\n",
        "    ship_channel = X_train[Y_train == 0, :, :, channel]\n",
        "    iceberg_channel = X_train[Y_train == 1, :, :, channel]\n",
        "    \n",
        "    print(f\"  Ships - Mean: {ship_channel.mean():.4f}, Std: {ship_channel.std():.4f}\")\n",
        "    print(f\"  Icebergs - Mean: {iceberg_channel.mean():.4f}, Std: {iceberg_channel.std():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Multi-Channel Image Comparison\n",
        "def compare_channels(X, y, sample_idx=None):\n",
        "    \"\"\"Compare all three channels for sample images\"\"\"\n",
        "    if sample_idx is None:\n",
        "        # Select random samples from each class\n",
        "        ship_idx = np.random.choice(np.where(y == 0)[0])\n",
        "        iceberg_idx = np.random.choice(np.where(y == 1)[0])\n",
        "        sample_indices = [ship_idx, iceberg_idx]\n",
        "        class_names = ['Ship', 'Iceberg']\n",
        "    else:\n",
        "        sample_indices = [sample_idx]\n",
        "        class_names = ['Ship' if y[sample_idx] == 0 else 'Iceberg']\n",
        "    \n",
        "    fig, axes = plt.subplots(len(sample_indices), 4, figsize=(16, 4 * len(sample_indices)))\n",
        "    if len(sample_indices) == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    for row, (idx, class_name) in enumerate(zip(sample_indices, class_names)):\n",
        "        # Display each channel\n",
        "        for channel in range(3):\n",
        "            im = axes[row, channel].imshow(np.squeeze(X[idx, :, :, channel]), cmap='gray')\n",
        "            axes[row, channel].set_title(f'{class_name} - Channel {channel}')\n",
        "            axes[row, channel].axis('off')\n",
        "            plt.colorbar(im, ax=axes[row, channel], fraction=0.046, pad=0.04)\n",
        "        \n",
        "        # RGB composite (if applicable)\n",
        "        if X.shape[3] >= 3:\n",
        "            # Normalize channels for RGB display\n",
        "            rgb_img = np.zeros((X.shape[1], X.shape[2], 3))\n",
        "            for c in range(3):\n",
        "                channel_data = X[idx, :, :, c]\n",
        "                rgb_img[:, :, c] = (channel_data - channel_data.min()) / (channel_data.max() - channel_data.min())\n",
        "            \n",
        "            axes[row, 3].imshow(rgb_img)\n",
        "            axes[row, 3].set_title(f'{class_name} - RGB Composite')\n",
        "            axes[row, 3].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "compare_channels(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Image-level Statistics and Features\n",
        "def calculate_image_features(X, y):\n",
        "    \"\"\"Calculate various statistical features for each image\"\"\"\n",
        "    features = {\n",
        "        'mean_intensity': [],\n",
        "        'std_intensity': [],\n",
        "        'min_intensity': [],\n",
        "        'max_intensity': [],\n",
        "        'contrast': [],  # std/mean\n",
        "        'brightness': []  # mean across all channels\n",
        "    }\n",
        "    \n",
        "    for i in range(len(X)):\n",
        "        img = X[i]\n",
        "        \n",
        "        # Overall statistics\n",
        "        features['mean_intensity'].append(img.mean())\n",
        "        features['std_intensity'].append(img.std())\n",
        "        features['min_intensity'].append(img.min())\n",
        "        features['max_intensity'].append(img.max())\n",
        "        features['contrast'].append(img.std() / (img.mean() + 1e-8))\n",
        "        features['brightness'].append(img.mean())\n",
        "    \n",
        "    return features\n",
        "\n",
        "# Calculate features\n",
        "print(\"Calculating image-level features...\")\n",
        "features = calculate_image_features(X_train, Y_train)\n",
        "\n",
        "# Convert to arrays for easier analysis\n",
        "feature_arrays = {k: np.array(v) for k, v in features.items()}\n",
        "\n",
        "# Plot feature distributions by class\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "feature_names = list(feature_arrays.keys())\n",
        "for i, feature_name in enumerate(feature_names):\n",
        "    ship_values = feature_arrays[feature_name][Y_train == 0]\n",
        "    iceberg_values = feature_arrays[feature_name][Y_train == 1]\n",
        "    \n",
        "    axes[i].hist(ship_values, bins=30, alpha=0.6, label='Ships', density=True, color='skyblue')\n",
        "    axes[i].hist(iceberg_values, bins=30, alpha=0.6, label='Icebergs', density=True, color='lightcoral')\n",
        "    axes[i].set_title(f'{feature_name.replace(\"_\", \" \").title()} Distribution')\n",
        "    axes[i].set_xlabel(feature_name.replace(\"_\", \" \").title())\n",
        "    axes[i].set_ylabel('Density')\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistical comparison\n",
        "print(\"\\n=== FEATURE COMPARISON BY CLASS ===\")\n",
        "for feature_name in feature_names:\n",
        "    ship_values = feature_arrays[feature_name][Y_train == 0]\n",
        "    iceberg_values = feature_arrays[feature_name][Y_train == 1]\n",
        "    \n",
        "    print(f\"\\n{feature_name.replace('_', ' ').title()}:\")\n",
        "    print(f\"  Ships     - Mean: {ship_values.mean():.4f}, Std: {ship_values.std():.4f}\")\n",
        "    print(f\"  Icebergs  - Mean: {iceberg_values.mean():.4f}, Std: {iceberg_values.std():.4f}\")\n",
        "    print(f\"  Difference: {abs(ship_values.mean() - iceberg_values.mean()):.4f}\")\n",
        "    \n",
        "    # Simple t-test (assuming normal distribution)\n",
        "    from scipy import stats\n",
        "    t_stat, p_value = stats.ttest_ind(ship_values, iceberg_values)\n",
        "    print(f\"  T-test p-value: {p_value:.6f} {'(Significant)' if p_value < 0.05 else '(Not significant)'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Correlation Analysis and Data Quality\n",
        "# Feature correlation matrix\n",
        "import pandas as pd\n",
        "\n",
        "# Create DataFrame for easier analysis\n",
        "feature_df = pd.DataFrame(feature_arrays)\n",
        "feature_df['class'] = Y_train\n",
        "\n",
        "# Correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "correlation_matrix = feature_df.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, fmt='.3f')\n",
        "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Data quality checks\n",
        "print(\"=== DATA QUALITY ANALYSIS ===\")\n",
        "\n",
        "# Check for missing or invalid values\n",
        "print(f\"Images with NaN values: {np.isnan(X_train).any(axis=(1,2,3)).sum()}\")\n",
        "print(f\"Images with infinite values: {np.isinf(X_train).any(axis=(1,2,3)).sum()}\")\n",
        "print(f\"Labels with invalid values: {((Y_train != 0) & (Y_train != 1)).sum()}\")\n",
        "\n",
        "# Check for duplicate images (simplified check using mean values)\n",
        "print(f\"\\nChecking for potential duplicates...\")\n",
        "image_means = X_train.mean(axis=(1,2,3))\n",
        "unique_means = len(np.unique(np.round(image_means, 6)))\n",
        "print(f\"Unique mean values: {unique_means} out of {len(X_train)} images\")\n",
        "if unique_means < len(X_train):\n",
        "    print(f\"âš ï¸  Potential duplicates detected: {len(X_train) - unique_means} images\")\n",
        "else:\n",
        "    print(\"âœ… No obvious duplicates found\")\n",
        "\n",
        "# Channel-wise anomaly detection (simple outlier detection)\n",
        "print(f\"\\n=== OUTLIER DETECTION ===\")\n",
        "for channel in range(3):\n",
        "    channel_means = X_train[:, :, :, channel].mean(axis=(1,2))\n",
        "    Q1 = np.percentile(channel_means, 25)\n",
        "    Q3 = np.percentile(channel_means, 75)\n",
        "    IQR = Q3 - Q1\n",
        "    outliers = ((channel_means < Q1 - 1.5 * IQR) | (channel_means > Q3 + 1.5 * IQR)).sum()\n",
        "    print(f\"Channel {channel} outliers: {outliers} images ({outliers/len(X_train)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. EDA Summary and Recommendations\n",
        "print(\"=\" * 60)\n",
        "print(\"                    EDA SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\"\"\n",
        "ðŸ“Š DATASET OVERVIEW:\n",
        "   â€¢ Total samples: {len(X_train):,}\n",
        "   â€¢ Image dimensions: {X_train.shape[1]}x{X_train.shape[2]} pixels\n",
        "   â€¢ Channels: {X_train.shape[3]} (likely radar bands)\n",
        "   â€¢ Classes: Ships ({(Y_train == 0).sum():,}) vs Icebergs ({(Y_train == 1).sum():,})\n",
        "   \n",
        "ðŸŽ¯ CLASS BALANCE:\n",
        "   â€¢ Ships: {(Y_train == 0).sum()/len(Y_train)*100:.1f}%\n",
        "   â€¢ Icebergs: {(Y_train == 1).sum()/len(Y_train)*100:.1f}%\n",
        "   â€¢ Balance ratio: {max(np.bincount(Y_train.astype(int)))/min(np.bincount(Y_train.astype(int))):.2f}:1\n",
        "   \n",
        "ðŸ“ˆ KEY INSIGHTS:\n",
        "   â€¢ Pixel intensities range from {X_train.min():.4f} to {X_train.max():.4f}\n",
        "   â€¢ Different channels show varying intensity distributions\n",
        "   â€¢ Some statistical differences exist between ship and iceberg features\n",
        "   \n",
        "ðŸ”§ RECOMMENDATIONS FOR MODEL DEVELOPMENT:\n",
        "\"\"\")\n",
        "\n",
        "# Generate specific recommendations based on findings\n",
        "recommendations = []\n",
        "\n",
        "# Class balance\n",
        "imbalance_ratio = max(np.bincount(Y_train.astype(int))) / min(np.bincount(Y_train.astype(int)))\n",
        "if imbalance_ratio > 1.5:\n",
        "    recommendations.append(\"   â€¢ Consider class balancing techniques (SMOTE, weighted loss, etc.)\")\n",
        "else:\n",
        "    recommendations.append(\"   â€¢ âœ… Dataset is well-balanced\")\n",
        "\n",
        "# Data preprocessing\n",
        "recommendations.extend([\n",
        "    \"   â€¢ Normalize pixel values (consider StandardScaler or MinMaxScaler)\",\n",
        "    \"   â€¢ Apply data augmentation (rotation, flipping, noise) to increase dataset size\",\n",
        "    \"   â€¢ Consider multi-channel feature engineering or channel selection\"\n",
        "])\n",
        "\n",
        "# Model suggestions\n",
        "recommendations.extend([\n",
        "    \"   â€¢ Try CNN architectures (ResNet, EfficientNet, VGG) for image classification\",\n",
        "    \"   â€¢ Use transfer learning from pre-trained models\",\n",
        "    \"   â€¢ Implement cross-validation for robust model evaluation\",\n",
        "    \"   â€¢ Consider ensemble methods combining multiple models\"\n",
        "])\n",
        "\n",
        "# Specific to radar data\n",
        "recommendations.extend([\n",
        "    \"   â€¢ Experiment with different radar band combinations\",\n",
        "    \"   â€¢ Apply radar-specific preprocessing if domain knowledge available\",\n",
        "    \"   â€¢ Consider edge detection or texture analysis features\"\n",
        "])\n",
        "\n",
        "for rec in recommendations:\n",
        "    print(rec)\n",
        "\n",
        "print(f\"\"\"\n",
        "ðŸ“‹ NEXT STEPS:\n",
        "   1. Data preprocessing and normalization\n",
        "   2. Train/validation split with stratification\n",
        "   3. Baseline model development (simple CNN)\n",
        "   4. Hyperparameter tuning and model optimization\n",
        "   5. Performance evaluation with multiple metrics\n",
        "   \n",
        "ðŸ’¡ IMPORTANT NOTES:\n",
        "   â€¢ This appears to be radar/satellite imagery - domain-specific preprocessing may help\n",
        "   â€¢ The 3-channel structure suggests multi-spectral or multi-polarization data\n",
        "   â€¢ Consider the physical meaning of each channel for better feature engineering\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random Forest Classifier\n",
        "\n",
        "Now, let's build a Random Forest model to classify ships and icebergs. We'll start by preparing the data, then train the model, and finally evaluate its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Data Preparation\n",
        "# Flatten the images from (num_samples, 80, 80, 3) to (num_samples, 80*80*3)\n",
        "num_samples = X_train.shape[0]\n",
        "X_train_flat = X_train.reshape(num_samples, -1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "# We'll use 80% for training and 20% for testing\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(\n",
        "    X_train_flat, \n",
        "    Y_train, \n",
        "    test_size=0.2, \n",
        "    random_state=42, \n",
        "    stratify=Y_train  # Ensure same class distribution in train/test\n",
        ")\n",
        "\n",
        "print(\"=== DATA PREPARATION COMPLETE ===\")\n",
        "print(f\"Shape of flattened training data: {X_train_rf.shape}\")\n",
        "print(f\"Shape of testing data: {X_test_rf.shape}\")\n",
        "print(f\"Training labels: {y_train_rf.shape[0]}\")\n",
        "print(f\"Testing labels: {y_test_rf.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Random Forest Regressor (For Demonstration)\n",
        "\n",
        "As mentioned, a regressor is not the ideal tool for this classification problem. However, to fulfill your request, here is how you would implement a `RandomForestRegressor` on the same dataset. We will treat the class labels (0 and 1) as continuous values, which is not standard practice for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 2. Model Training\n",
        "# Initialize the Random Forest Regressor\n",
        "# n_estimators: number of trees in the forest\n",
        "# random_state: for reproducibility\n",
        "regressor = RandomForestRegressor(n_estimators=100, random_state=42, oob_score=True, n_jobs=-1)\n",
        "\n",
        "print(\"=== TRAINING RANDOM FOREST REGRESSOR ===\")\n",
        "regressor.fit(X_train_rf, y_train_rf)\n",
        "print(\"Training complete.\")\n",
        "print(f\"Out-of-Bag (OOB) Score: {regressor.oob_score_:.4f}\")\n",
        "\n",
        "# 3. Prediction\n",
        "print(\"\\n=== MAKING PREDICTIONS ===\")\n",
        "y_pred_reg = regressor.predict(X_test_rf)\n",
        "\n",
        "# 4. Evaluation\n",
        "print(\"\\n=== REGRESSOR EVALUATION ===\")\n",
        "mse = mean_squared_error(y_test_rf, y_pred_reg)\n",
        "r2 = r2_score(y_test_rf, y_pred_reg)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"R-squared (RÂ²): {r2:.4f}\")\n",
        "\n",
        "# To interpret the results in a classification context, we can round the predictions\n",
        "y_pred_rounded = np.round(y_pred_reg)\n",
        "accuracy_from_regressor = accuracy_score(y_test_rf, y_pred_rounded)\n",
        "\n",
        "print(f\"\\nAccuracy (from rounded predictions): {accuracy_from_regressor:.4f}\")\n",
        "\n",
        "# 5. Visualization of Predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(y_pred_reg, bins=50, kde=True)\n",
        "plt.title('Distribution of Raw Regressor Predictions', fontweight='bold')\n",
        "plt.xlabel('Predicted Value (0=Ship, 1=Iceberg)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.axvline(0.5, color='red', linestyle='--', label='Decision Boundary (0.5)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Polynomial Regression (PolynomialFeatures + Ridge) - self-contained\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"=== TRAINING POLYNOMIAL REGRESSION (PolynomialFeatures + Ridge) ===\")\n",
        "\n",
        "# Prepare flattened data and train/test split if not already available\n",
        "if 'X_train_rf' not in globals() or 'y_train_rf' not in globals() or 'X_test_rf' not in globals() or 'y_test_rf' not in globals():\n",
        "    print(\"X_train_rf or related variables not found. Preparing flattened data and train/test split...\")\n",
        "    # Expect X_train and Y_train to be in the notebook\n",
        "    try:\n",
        "        num_samples = X_train.shape[0]\n",
        "    except NameError:\n",
        "        raise NameError(\"X_train is not defined in the notebook. Please run the data loading cell first.\")\n",
        "\n",
        "    X_train_flat = X_train.reshape(num_samples, -1)\n",
        "    X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(\n",
        "        X_train_flat,\n",
        "        Y_train,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=Y_train\n",
        "    )\n",
        "    print(\"Flattening and split complete.\")\n",
        "else:\n",
        "    print(\"Found existing flattened data and splits. Reusing them.\")\n",
        "\n",
        "# Build pipeline: polynomial features (degree=2) + ridge regression\n",
        "degree = 2\n",
        "alpha = 1.0\n",
        "poly_pipeline = Pipeline([\n",
        "    (\"poly\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
        "    (\"ridge\", Ridge(alpha=alpha, random_state=42))\n",
        "])\n",
        "\n",
        "# Fit on flattened training data\n",
        "poly_pipeline.fit(X_train_rf, y_train_rf)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Predict and evaluate (regression metrics)\n",
        "y_pred_reg = poly_pipeline.predict(X_test_rf)\n",
        "print(f\"MSE: {mean_squared_error(y_test_rf, y_pred_reg):.4f}\")\n",
        "print(f\"R^2: {r2_score(y_test_rf, y_pred_reg):.4f}\")\n",
        "\n",
        "# Convert to classification by rounding and clipping\n",
        "y_pred_rounded = np.clip(np.round(y_pred_reg).astype(int), 0, 1)\n",
        "acc = accuracy_score(y_test_rf, y_pred_rounded)\n",
        "print(f\"Accuracy (after rounding): {acc:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_rf, y_pred_rounded))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test_rf, y_pred_rounded)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(f'Confusion Matrix - Polynomial Regression (deg={degree})')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# Distribution of raw predictions\n",
        "plt.figure(figsize=(10,4))\n",
        "sns.histplot(y_pred_reg, bins=50, kde=True)\n",
        "plt.title('Distribution of Polynomial Regression Predictions')\n",
        "plt.xlabel('Predicted value (continuous)')\n",
        "plt.axvline(0.5, color='red', linestyle='--', label='Decision boundary (0.5)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Save pipeline\n",
        "model_path = 'polynomial_regressor.joblib'\n",
        "joblib.dump(poly_pipeline, model_path)\n",
        "print(f\"Model saved to {model_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
