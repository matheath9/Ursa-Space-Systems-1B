# -*- coding: utf-8 -*-
"""LoadDataTest

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z2J0zEPAfBLrLOp2GDPykjDcd7LHyteb
"""

!pip install py7zr

import pandas as pd
import numpy as np
import py7zr
import os
import matplotlib.pyplot as plt
import seaborn as sns

"""https://www.kaggle.com/code/suchadapleasong/iceberg

**`EXPLORATORY DATA ANALYSIS`**
"""

import zipfile
import os

zipfile_path = '/kaggle/statoil-iceberg-classifier-challenge.zip'

with zipfile.ZipFile(zipfile_path, "r") as z:
    z.extractall("/kaggle/working")   # extract to working directory

with zipfile.ZipFile(zipfile_path, "r") as z1:
    z1.extractall("/kaggle/working")

# check what files are extracted
print(os.listdir("/kaggle/working"))

with py7zr.SevenZipFile('/kaggle/working/train.json.7z', mode='r') as z:
    z.extractall()
    #print(z.getnames())

with py7zr.SevenZipFile('/kaggle/working/test.json.7z', mode='r') as z1:
    z1.extractall()
    #print(z1.getnames())

"""The pixel intensity values are often converted to a physical quantity called the backscattering coefficient or normalised radar cross-section measured in decibel (dB) units with values ranging from +5 dB for very bright objects to -40 dB for very dark surfaces."""

# data/processed/test.json
# data/processed/train.json

train = pd.read_json('data/processed/train.json')
test = pd.read_json('data/processed/test.json')
# train.head(5)
test.head(5)

# check if there are null values in any column
inc_angle_na = train['inc_angle'].isna().sum()
is_iceberg_na = train['is_iceberg'].isna().sum()
band_1_na = train['band_1'].isna().sum()
band_2_na = train['band_2'].isna().sum()

print(f'inc_angle_na: {inc_angle_na}')
print(f'is_iceberg_na: {is_iceberg_na}')
print(f'inc_angle_na: {band_1_na}')
print(f'is_iceberg_na: {band_2_na}')

# drop id columns in test and train, not needed
# train.drop('id', axis=1, inplace = True)
# test.drop('id', axis=1, inplace = True)

total_num_icebergs = train['is_iceberg'] == 1
print("is iceberg:" , total_num_icebergs.sum())

total_num_ships = train['is_iceberg'] == 0
print("is ship:   " , total_num_ships.sum())

# each array in band_1 and band_2 has 5625 values.
band_1 = np.array(train['band_1'].head())
band_2 = np.array(train['band_2'].head())

print ("band 1 array size:", len(band_1[0]))
print ("band 2 array size:", len(band_2[0]))

# get singular values for band1 mean, median, standard deviation (can't do unless I loop through every 5626 length array and get the standard deviation of each row)
band1_mean = np.mean(np.mean(band_1))
band1_median = np.median(np.median(band_1))
#band1_std = np.std(band_1)

print("\nband_1 mean:", band1_mean)
print("band_1 median:", band1_median)
#print(band1_std)

# get singular values for band2 mean, median, standard deviation
band2_mean = np.mean(np.mean(band_2))
band2_median = np.median(np.median(band_2))
#band2_std = np.std(band_2)

print("\nband_2 mean:", band2_mean)
print("band_2 median:", band2_median)
#print(band2_std)

"""https://www.kaggle.com/code/suchadapleasong/iceberg

**`RESCALE IMAGES + ADD THIRD BAND`**
"""

def get_scaled_imgs(df):
    imgs = []

    for i, row in df.iterrows():

        # make 75x75 image
        band_1 = np.array(row['band_1']).reshape(75, 75)
        band_2 = np.array(row['band_2']).reshape(75, 75)
        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)

        a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())
        b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())
        c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())

        imgs.append(np.dstack((a, b, c)))
    return np.array(imgs)

data = get_scaled_imgs(train) # use this on the train set
target = np.array(train['is_iceberg']) # used to print out just the labels from is_iceberg

print(data.shape)
print(target.shape)

# view images
fig = plt.figure(figsize=(10, 7))
rows = 5
columns = 5

for i in range(5):
    fig.add_subplot(rows, columns, i+1)
    plt.imshow(data[i])

print(target[:5]) # label for the first 5 images

"""**`RANDOM FOREST REGRESSOR`**"""

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

data = data.reshape(data.shape[0], -1)

x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=1234)

# CURRENTLY NOT WORKING (taking too long to run)
# i will test the random forest regressor on a smaller sample size
'''
rf_model = RandomForestRegressor(max_depth=16, n_estimators=100)
rf_model.fit(x_train, y_train)
y_rf_pred = rf_model.predict(x_test)
rf_rmse = mean_squared_error(y_test, y_rf_pred, squared=False)
rf_r2 = r2_score(y_test, y_rf_pred)

print('[RF] Root Mean Squared Error: {0}'.format(rf_rmse))
print('[RF] R2: {0}'.format(rf_r2))
'''

"""**`ConvNeXT - Getting Embeddings from Test Data`**"""

from PIL import Image
from transformers import AutoImageProcessor, ConvNextForImageClassification
import torch

#load and preprocess data
processor = AutoImageProcessor.from_pretrained("facebook/convnext-tiny-224")

batch = test.iloc[:50] # test on first 50 images - doesn't work for me if I run all images

# normalize band between 0 and 1
def normalize_band(band):
    band_min = band.min()
    band_max = band.max()
    return (band - band_min) / (band_max - band_min + 1e-6)

# has to have 3 bands, so reshape band_1 and band_2, average band_1 and band_2 for band_3
def scale_test_imgs(row):
    band_1 = np.array(row.band_1).reshape(75, 75)
    band_2 = np.array(row.band_2).reshape(75, 75)
    band_3 = (band_1 + band_2) / 2

    # normalize bands to [0,1]
    band_1 = normalize_band(band_1)
    band_2 = normalize_band(band_2)
    band_3 = normalize_band(band_3)

    # stack
    img = np.stack([band_1, band_2, band_3], axis=-1)  # shape: (75,75,3)
    return (img * 255).astype(np.uint8)

# convert to PIL
test_images_pil = [Image.fromarray(scale_test_imgs(row)) for _, row in batch.iterrows()]
processor = AutoImageProcessor.from_pretrained("facebook/convnext-base-224")

# feed images to HuggingFace processor
inputs = processor(images=test_images_pil, return_tensors="pt")

# load ConvNeXT model
model = ConvNextForImageClassification.from_pretrained(
    "facebook/convnext-base-224",
    num_labels=2, # for binary classification
    ignore_mismatched_sizes=True
)
model.eval()

# move to GPU if available
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)
inputs = {k: v.to(device) for k, v in inputs.items()}
# will give a warning

# make predictions and get predicted labels
with torch.no_grad():
    outputs = model(**inputs)
    predicted_labels = outputs.logits.argmax(dim=1).cpu().numpy()  # 0 or 1

# print predicted labels for the first 50 images
print(predicted_labels)

# save to pkl file
import pickle

pkl_filename = "ConvNeXT_test_images.pkl"

# save list of images
with open(pkl_filename, "wb") as f:
    pickle.dump(test_images_pil, f)

print(f"Saved {len(test_images_pil)} images to {pkl_filename}")
